
<!-- <div class="bg">
    <div class="container-fluid"style="width: 100%; height: 100%; ">
        <div class="container" style="width: 100%; height: 100%; ">
            <div class="col-md-12 col-sm-12 d-flex justify-content-center mt-3">
                <h1>Passion over Data</h1>
            </div>
            <div class="col-md-12 col-sm-12 d-flex justify-content-center">
                <p>Building dashboards with a "passion over data" approach which mean focusing  on creating visually appealing, engaging, and user-friendly designs with prioritizing data accuracy, complexity, or quantity. From my professional experience, I have worked extensively on building dashboards. This involved utilizing SSAS services and conducting ETL operations, including the development and maintenance of pipelines.</p>
            </div>
            <p>Some of my Dashboards down here üëáüèº</p>
        </div> 
     <div>
</div> -->


<div id="pro111">
    <div class="container-fluid"style="width: 100%; height: 100%; ">
        <div class="container" style="width: 100%; height: 100%; ">
            <div class="row d-flex">
                <div class="col-xl-6 col-sm-6 col-12 mt-2 mb-5">
                    <div class="home-content">
                      <h1 style="color: rgb(0, 0, 0); margin-top: 6rem; font-size:4rem;">Passion over Data!</h1>
                      <h6 style="color: rgb(0,0,0);">Know More about My Data Journey</h6>
                      <p>I am a dedicated Data Engineer with a strong passion for transforming raw data into meaningful insights. My journey in cloud technologies, especially AWS, has equipped me with the skills to build and optimize data pipelines, perform efficient ETL processes, and manage large-scale data infrastructures. I specialize in creating data solutions that are both scalable and user-centric, ensuring that the data is not only accessible but also actionable.</p>
                     <!-- This is a comment  <h3>And I'm a <span class="text"></span></h3> -->
                      <p>
                      </p>
                       
                    </div>
                  
                </div>
                <div class="col-xl-6 col-sm-6 col-12 mt-2 mb-5">
                   
                    <img [src]="'../assets/images/dashboardgif.gif'" class="img-fluid mt-5" style="height: 300px; border-radius: 2rem;" id="gif">
                    
                </div>
    
            </div>
   </div> 
   <div>
  </div>

  
<!-- <div id="pro111">
    <div class="container-fluid"style="width: 100%; height: 100%; ">
        <div class="container" style="width: 100%; height: 100%; ">
            <div class="row d-flex">
                <div class="col-xl-6 col-sm-6 col-12 mt-2 mb-5">
                    <div class="home-content">
                      
                      <h3 style="color: rgb(0,0,0);">Certified Data Engineer</h3>
                      <p>I am proud to have earned my AWS Data Engineer certification, which reflects my expertise in designing, implementing, and managing cloud-based data solutions. Through this certification journey, I gained hands-on experience with key AWS services such as S3, Redshift, Glue, Lambda, and more. This achievement demonstrates my ability to build robust, scalable data pipelines, perform efficient ETL processes, and ensure secure and cost-effective cloud solutions.

                        The certification has solidified my skills in cloud architecture, data migration, and real-time data processing, empowering me to deliver high-performance data infrastructures that drive business insights.</p>
                     This is a comment  <h3>And I'm a <span class="text"></span></h3>
                     <a class="nav-link" target="_blank" href="https://www.credly.com/badges/c2603eec-0ae0-435f-948d-b2ea2804e2c7/linked_in_profile"><p id="dashboard" style="color: brown;">Certificate</p></a>
                       
                    </div>
                  
                </div>
                <div class="col-xl-6 col-sm-6 col-12 mt-2 mb-5">
                   
                    <img [src]="'../assets/images/data_engineer.png'" class="img-fluid mt-5" style="height: 300px; border-radius: 2rem;" id="gif">
                   
                    
                </div>
    
            </div>
   </div> 
   <div>
  </div> -->



  <!-- <div id="pro111">
    <div class="container-fluid"style="width: 100%; height: 100%; ">
        <div class="container" style="width: 100%; height: 100%; ">
            <div class="row d-flex">
                <div class="col-xl-12 col-sm-12 col-12 mt-2 mb-5">
                    <div class="home-content">
                      
                      <h3 style="color: rgb(0,0,0);">Certified Data Engineer</h3>
                      <p>I am proud to have earned my AWS Data Engineer certification, which reflects my expertise in designing, implementing, and managing cloud-based data solutions. Through this certification journey, I gained hands-on experience with key AWS services such as S3, Redshift, Glue, Lambda, and more. This achievement demonstrates my ability to build robust, scalable data pipelines, perform efficient ETL processes, and ensure secure and cost-effective cloud solutions.

                        The certification has solidified my skills in cloud architecture, data migration, and real-time data processing, empowering me to deliver high-performance data infrastructures that drive business insights.</p>
                     <a class="nav-link" target="_blank" href="https://www.credly.com/badges/c2603eec-0ae0-435f-948d-b2ea2804e2c7/linked_in_profile"><p id="dashboard" style="color: brown;">Certificate</p></a>
                       <div class="text-center">
                        <img [src]="'../assets/images/data_engineer.png'" class="img-fluid mt-5" style="height: 300px; border-radius: 2rem;" id="gif">


                       </div>
                    </div>
                  
                </div>
    
            </div>
   </div> 
   <div>
  </div> -->
























  <!-- <div class="container">
    <div class="row mt-2 mb-5">
        <div class="col-md-12 col-s-12">
            <div class="home-content1" data-aos="fade-left" data-aos-delay="200">
                <h1 style="color:#ca4f4f">Data Projects</h1>
                <h5 style="color: rgb(0, 0, 0); margin-top: 3rem; font-size: 1.3rem;">AWS ETL pipeline Project</h5>
                <div class="col-xl-12 col-sm-12 col-12 text-center">
                    <img src="../assets/images/glue.gif" class="img-fluid mt-5" style="height: 500px; border-radius: 2rem;">
                </div>
                <p>In this project, I built a data pipeline using AWS services. First, data is stored in Amazon S3, which acts as a staging area. Next, I used AWS Glue to clean and transform the data through an ETL (Extract, Transform, Load) process. After the data is prepared, an AWS Glue crawler automatically scans it and sends it to Amazon Athena, where it can be queried easily. Finally, the processed data is visualized in Amazon QuickSight, allowing the client to gain insights and make informed decisions.</p>
           <p>Scalability and Operational Efficiency:

           <br> <b>On-Demand Scalability:</b> The use of AWS Glue for ETL and crawlers, along with Amazon Athena for querying, allows the pipeline to scale according to the volume of data and query load, accommodating changing requirements without significant manual intervention.
            
        <br><b> Low Operational Overhead:</b> This orchestration minimizes the need for extensive management and maintenance efforts, allowing your team to focus on data insights rather than infrastructure management.
            
       <br> <b>Good Latency:</b> Despite the slightly higher costs, the combination of these services ensures efficient processing and querying, delivering insights quickly to support informed decision-making.</p>
            </div>
        </div>
    </div>
</div>

<div class="container">
    <div class="row mt-2 mb-5">
        <div class="col-md-12 col-s-12">
            <div class="home-content1" data-aos="fade-left" data-aos-delay="200">
                <h3 style="color: rgb(0, 0, 0); margin-top: 3rem; font-size: 2rem;">Exploratory Data Analysis (EDA) Using Apache Spark Leveraging Databricks.</h3>
                <div class="col-xl-12 col-sm-12 col-12 text-center">
                    <img src="../assets/images/s3_databricks_spark_sql_viz.gif" class="img-fluid mt-5" style="height: 500px; border-radius: 2rem;">
                </div>
                <p>IPL Data Analysis Workflow
                    I developed a robust data processing workflow for analyzing IPL (Indian Premier League) data:
                    
                    <br><b>Data Ingestion</b>: IPL data is received from various sources and stored in Amazon S3 for scalable and durable storage.
                    
                    <br><b>Data Processing in Databricks:</b>
                    
                    The data is ingested into Databricks, where I perform data cleaning and transformation to ensure quality and consistency.
                    I run complex SQL queries to analyze player performances, match outcomes, and team statistics.</p>
            </div>
            <a href="https://github.com/bairidilipkumar/aws/tree/main/project_spark_databricks_ipl" target="_blank">GitLink</a>
        </div>
    </div>
</div>

<div class="container">
    <div class="row mt-2 mb-5">
        <div class="col-md-12 col-s-12">
            <div class="home-content1" data-aos="fade-left" data-aos-delay="200">
                <h3 style="color: rgb(0, 0, 0); margin-top: 3rem; font-size: 2rem;">Airflow orchestration using API.</h3>
                <div class="col-xl-12 col-sm-12 col-12 text-center">
                    <img src="../assets/images/airflow.gif" class="img-fluid mt-5" style="height: 500px; border-radius: 2rem;">
                </div>
                <p>Airflow is used to orchestrat the tasks by creating DAG's so i did this project to know more about airflow workflow.
                    
                    <br><b>API Integration:</b> Configured Airflow to connect with the Open Weather API, enabling automated data extraction based on predefined schedules.

                    <br><b>Data Extraction:</b> Created a task to fetch weather data from the API, ensuring relevant parameters were collected for further processing.

                    <br><b>Data Processing:</b> Implemented transformations on the extracted data, cleaning and organizing it to meet storage and analysis requirements.

                    <br><b>Data Storage:</b> Developed a task to store the processed data in Amazon S3, ensuring it was securely saved and easily accessible for future use.</p>
            </div>
            <a href="https://github.com/bairidilipkumar/aws/tree/main/project_spark_databricks_ipl" target="_blank">GitLink</a> 
        </div>
    </div>
</div> -->





<div class="row justify-content-around mt-3 mb-5">
  <div class="card mt-5 shadow-effect" style="max-width: 40rem; max-height: 65rem;">
    <div class="card-body">
      <div class="row justify-content-center">
        <p class="card-title">AWS ETL pipeline Project </p>
        <hr>
        <br>
        <img src="../assets/images/glue.gif" class="img-fluid" style="height: 300px; width: 600px;"
             data-bs-toggle="modal" data-bs-target="#imageModal-glue" onclick="showImage(this)">
        <b class="card-text">Explanation </b><p class="hiddentext" style="color: aliceblue;">(Click on the image "‚Üó" For full Explanation)</p>
        <p>In this project, I built a data pipeline using AWS services. First, data is stored in Amazon S3, which acts as a staging area. Next, I used AWS Glue to clean and transform the data through an ETL (Extract, Transform, Load) process. After the data is prepared, an AWS Glue crawler automatically scans it and sends it to Amazon Athena, where it can be queried easily. Finally, the processed data is visualized in Amazon QuickSight, allowing the client to gain insights and make informed decisions.</p>
           <p>Scalability and Operational Efficiency:
            <br><p>Read More...</p>
      </div>
    </div>
  </div>

  <div class="card mt-5 shadow-effect" style="max-width: 40rem; max-height: 65rem;">
    <div class="card-body">
      <div class="row justify-content-center">
        <p class="card-title">Orchestrating weather API with Airflow to S3</p>
        <hr>
        <br>
        <img src="../assets/images/weather-api-s3-email.svg" class="img-fluid mb-3" style="height: 300px; width: 600px;"
             data-bs-toggle="modal" data-bs-target="#imageModal-airflow-s3" onclick="showImage(this)">
        <b class="card-text">Explanation</b><p class="hiddentext" style="color: aliceblue;">(Click on the image "‚Üó" For full Explanation and Source Code)</p>
        <p>This project extends the functionality of a Weather API by integrating several key components to streamline the process of gathering and distributing weather data.

          <br><b>Data Orchestration with Airflow:</b> Initially, we orchestrate the fetching of weather data using Apache Airflow. This allows us to automate the data collection process efficiently.
          
       <br> <b> Storing Data in S3:</b> Once the data is fetched, it is stored in Amazon S3 (Simple Storage Service). S3 serves as a reliable storage solution, ensuring that our weather data is easily accessible and secure.
          
     <br> <b>Triggering Processing with S3 Events:</b> To enhance the responsiveness of our system, </p>
     <br><p>Read More...</p>
      </div>
    </div>
  </div>
</div>


<div class="row justify-content-around mt-3 mb-5">
  <div class="card mt-5 shadow-effect" style="max-width: 40rem; max-height: 65rem;">
    <div class="card-body">
      <div class="row justify-content-center">
        <p class="card-title">Exploratory Data Analysis (EDA) Using Apache Spark Leveraging Databricks</p>
        <hr>
        <br>
        <img src="../assets/images/databricks.svg" class="img-fluid" style="height: 300px; width: 600px;"
             data-bs-toggle="modal" data-bs-target="#imageModal-databricks-s3" onclick="showImage(this)">
        <b class="card-text">Explanation </b><p class="hiddentext" style="color: aliceblue;">(Click on the image "‚Üó" For full Explanation and Source Code)</p>
        <p>IPL Data Analysis Workflow
          I developed a robust data processing workflow for analyzing IPL (Indian Premier League) data:
          
          <br><b>Data Ingestion</b>: IPL data is received from various sources and stored in Amazon S3 for scalable and durable storage.
          
          <br><b>Data Processing in Databricks:</b></p>
          <br><p>Read More...</p>
      </div>
    </div>
  </div>

  <div class="card mt-5 shadow-effect" style="max-width: 40rem; max-height: 65rem;">
    <div class="card-body">
      <div class="row justify-content-center">
        <p class="card-title">Orchestrating weather API</p>
        <hr>
        <br>
        <img src="../assets/images/Normal-weather-api-airflow.svg" class="img-fluid mb-3" style="height: 300px; width: 600px;"
             data-bs-toggle="modal" data-bs-target="#imageModal-weather-api" onclick="showImage(this)">
        <b class="card-text">Explanation</b><p class="hiddentext" style="color: aliceblue;">(Click on the image "‚Üó" For full Explanation and Source Code)</p>
        <p>Airflow is used to orchestrat the tasks by creating DAG's so i did this project to know more about airflow workflow.
                    
          <br><b>API Integration:</b> Configured Airflow to connect with the Open Weather API, enabling automated data extraction based on predefined schedules.

          <br><b>Data Extraction:</b> Created a task to fetch weather data from the API, ensuring relevant parameters were collected for further processing.</p>
          <br><p>Read More...</p>
      </div>
    </div>
  </div>
  
</div>



<div class="row justify-content-around mt-3 mb-5">
  <div class="card mt-5 shadow-effect" style="max-width: 40rem; max-height: 65rem;">
    <div class="card-body">
      <div class="row justify-content-center">
        <p class="card-title">Amazon Data Engineering Books Scraping and Visualization Pipeline</p>
        <hr>
        <br>
        <img src="../assets/images/amazon-web-scraping.svg" class="img-fluid" style="height: 300px; width: 600px;"
             data-bs-toggle="modal" data-bs-target="#imageModal-amazon-book" onclick="showImage(this)">
        <b class="card-text">Explanation </b><p class="hiddentext" style="color: aliceblue;">(Click on the image "‚Üó" For full Explanation and Source Code)</p>
        <p>Amazon web Scarping
        <br>  This project automates the process of collecting, transforming, and visualizing data related to data engineering books available on Amazon. 
        <br>   The data is collected via API and web scraping, transformed into a structured format, and stored in a PostgreSQL database. The stored data 
        <br>  is then connected to Power BI for real-time visualization, ensuring continuous insights into trending books in the data engineering field.
        <br><p>Read More...</p>
      </div>
    </div>
  </div>

  <div class="card mt-5 shadow-effect" style="max-width: 40rem; max-height: 65rem;">
    <div class="card-body">
      <div class="row justify-content-center">
        <p class="card-title">Heart Disease Prediction and Exploratory Data Analysis (EDA)</p>
        <hr>
        <br>
        <img src="../assets/images/heart-eda.jfif" class="img-fluid mb-3" style="height: 300px; width: 600px;"
             data-bs-toggle="modal" data-bs-target="#imageModal-heart" onclick="showImage(this)">
        <b class="card-text">Explanation</b><p class="hiddentext" style="color: aliceblue;">(Click on the image "‚Üó" For full Explanation and Source Code)</p>
        <p>his project aims to predict the likelihood of heart disease in patients by analyzing medical data. A detailed exploratory data analysis (EDA)
           is conducted to uncover patterns and insights within the dataset. Machine learning models are then used to predict heart disease risk based 
           on key health indicators such as age, cholesterol levels, blood pressure, and more</p>
          <br><p>Read More...</p>
      </div>
    </div>
  </div>
  
</div>

<!-- modal of ABOVE 2 -->

<div class="modal fade" id="imageModal-amazon-book" tabindex="-1" aria-labelledby="imageModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-dialog-centered" style="max-width: 90vw; max-height: 90vh;">
    <div class="modal-content" style="height: auto; max-height: 100vh;">
      <div class="modal-header">
        <h5 class="modal-title" id="imageModalLabel-databricks-s3">Exploratory Data Analysis (EDA) Using Apache Spark Leveraging Databricks</h5>
        <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
      </div>
      <div class="modal-body text-center" style="height: calc(100% - 3.5rem); overflow-y: auto;">
        <img id="modalImage" src="../assets/images/amazon-web-scraping.svg" class="img-fluid" alt="EDA Project Image" style="max-width: 80%; height: auto; object-fit: contain;">
        
        <p><b>Data Collection:</b> Web scraping Amazon for the latest data engineering books using Python BeautifulSoup and requests libraries. Collecting key details like book titles, authors, ratings, prices, and availability. API integration (if available) to fetch additional metadata such as publication dates or customer reviews.<br>
        <b>Data Transformation:</b> Cleaning and structuring the raw data into a suitable format for analysis using pandas. Applying necessary transformations, such as data type conversions, handling missing values, and normalizing book categories.<br>
        <b>Data Storage (PostgreSQL):</b> Using PostgreSQL as the primary data store to maintain the up-to-date records of scraped data. Writing the transformed data into PostgreSQL using psycopg2 library. Ensuring data integrity and creating automated updates for newly scraped data.<br>
        <b>Visualization (Power BI):</b> Connecting Power BI to PostgreSQL for real-time access to the latest scraped data. Building interactive dashboards to visualize key metrics like the top-rated books, most popular authors, and price trends.</p>
        <br>
        <a href="https://github.com/bairidilipkumar/aws/tree/main/project_spark_databricks_ipl" target="_blank">GitLink</a>
      </div>
    </div>
  </div>
</div>

<div class="modal fade" id="imageModal-heart" tabindex="-1" aria-labelledby="imageModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-dialog-centered" style="max-width: 90vw; max-height: 90vh;">
    <div class="modal-content" style="height: auto; max-height: 100vh;">
      <div class="modal-header">
        <h5 class="modal-title" id="imageModalLabel-databricks-s3">Heart Disease Prediction and Exploratory Data Analysis (EDA)</h5>
        <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
      </div>
      <div class="modal-body text-center" style="height: calc(100% - 3.5rem); overflow-y: auto;">
        <img id="modalImage" src="../assets/images/heart-eda.jfif" class="img-fluid" alt="Heart EDA Project Image" style="max-width: 80%; height: auto; object-fit: contain;">
      
      <p><b>Exploratory Data Analysis (EDA):</b> Performing comprehensive EDA using Python libraries like pandas, matplotlib, and seaborn to understand the datasets structure and relationships. Visualizing the distribution of key features such as age, cholesterol levels, blood pressure, and target variables (presence or absence of heart disease). Identifying correlations between features, handling missing data, and outlier detection. Feature engineering by creating new variables from existing ones (e.g., age groups, cholesterol levels categorized into risk brackets).<br>
      
      <b>Data Preprocessing:</b> Scaling and normalizing data using techniques like Min-Max scaling and StandardScaler to prepare it for machine learning models. Splitting the dataset into training and test sets to evaluate model performance.<br>
      
      <b>Machine Learning Models:</b> Implementing classification models such as Logistic Regression, Random Forest, and Support Vector Machines (SVM) to predict the presence of heart disease. Hyperparameter tuning using grid search and cross-validation to optimize model performance. Evaluating models using metrics like accuracy, precision, recall, F1-score, and ROC-AUC curves.</p>
      
      <br>
      <a href="https://github.com/bairidilipkumar/MachineLearning_Models/blob/main/EDA%20and%20Pridiction%20of%20Heart%20Disease/Heart_EDA.ipynb" target="_blank">GitLink</a>
      </div>
    </div>
  </div>
</div>




<div class="row justify-content-around mt-3 mb-5">
  <div class="card mt-5 shadow-effect" style="max-width: 40rem; max-height: 65rem;">
    <div class="card-body">
      <div class="row justify-content-center">
        <p class="card-title">Amazon Data Engineering Books Scraping and Visualization Pipeline</p>
        <hr>
        <br>
        <img src="../assets/images/snowflake1.svg" class="img-fluid" style="height: 300px; width: 600px;"
             data-bs-toggle="modal" data-bs-target="#imageModal-snowflake1" onclick="showImage(this)">
        <b class="card-text">Explanation </b><p class="hiddentext" style="color: aliceblue;">(Click on the image "‚Üó" For full Explanation)</p>
        <p>This project focuses on creating a seamless, real-time data pipeline designed to handle high-velocity 
          data from diverse sources and deliver insights through Power BI. The pipeline begins with AWS S3, 
          where raw data is ingested and stored in a designated S3 bucket. Data then flows to Snowflake, 
          where it undergoes structured staging and transformation processes in the Snowflake warehouse, 
          ensuring data consistency, quality, and readiness for analysis.
        <br><p>Read More...</p>
      </div>
    </div>
  </div>
  
</div>

<div class="modal fade" id="imageModal-snowflake1" tabindex="-1" aria-labelledby="imageModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-dialog-centered" style="max-width: 90vw; max-height: 90vh;">
    <div class="modal-content" style="height: auto; max-height: 100vh;">
      <div class="modal-header">
        <h5 class="modal-title" id="imageModalLabel-databricks-s3">Exploratory Data Analysis (EDA) Using Apache Spark Leveraging Databricks</h5>
        <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
      </div>
      <div class="modal-body text-center" style="height: calc(100% - 3.5rem); overflow-y: auto;">
        <img id="modalImage" src="../assets/images/snowflake1.svg" class="img-fluid" alt="EDA Project Image" style="max-width: 80%; height: auto; object-fit: contain;">
        <br>
        Using Snowflake's robust querying and data transformation capabilities, the pipeline processes incoming data to
         support near-real-time updates. Processed data is then made available to Power BI, where dashboards display live 
         insights, allowing users to make data-driven decisions with minimal delay. This real-time setup enables fast, accurate reporting, 
         ideal for scenarios requiring continuous monitoring and timely responses.
        <br><b>Key Components and Features:</b>
      <br><b>AWS S3: </b>Data ingestion and raw data storage.
     <br> <b> Snowflake Staging and Warehouse: </b>Data transformation, cleansing, and preparation.
     <br> <b>Power BI Integration:</b> Real-time visualization and reporting for live business insights.
        <br> This solution offers high scalability and efficient data orchestration, making it ideal for dynamic environments requiring immediate data visibility and analysis
        <br>
       
      </div>
    </div>
  </div>
</div>













  <div id="pro111">
    <div class="container-fluid"style="width: 100%; height: 100%; ">
        <div class="container" style="width: 100%; height: 100%; ">
            <h5 style="font-size: 1rem; color: #ca4f4f;">With a deep love for working with data, I focus on designing visually appealing, intuitive, and data-driven dashboards that enable teams to make informed decisions. My goal is to merge technical expertise with a passion for delivering impactful, data-rich experiences, always prioritizing clean, well-structured, and reliable data</h5>
   </div> 
   <div>
  </div>
  


  

  <div class="row justify-content-around mt-3 mb-5">
    <div class="card mt-5" style="max-width: 40rem; max-height: 65rem;">
      <div class="card-body">
        <div class="row justify-content-center">
          <p>HR Dashboard </p>
          <hr>
          <br>
          <img src="../assets/images/hr_dashboard.PNG" class="img-fluid" style="height: 300px; width: 600px;"
               data-bs-toggle="modal" data-bs-target="#imageModal" onclick="showImage(this)">
          <b>Explanation </b><p>(Click on the image "‚Üó" )</p>
          <p>I created this dashboard using Power BI for a store owner to help analyze business performance. It starts with key details like total profits, total quantities sold, and overall sales. Next, the dashboard breaks down profits by different product subcategories and shows which months had the highest profits and losses.

            A donut chart highlights the total quantities sold by category, splitting sales into furniture, electronics, and clothing. There‚Äôs also a bar graph showing the states where the business did best, and a final donut chart displays the different payment methods used by customers.</p>
        </div>
      </div>
    </div>
  
    <div class="card mt-5" style="max-width: 40rem; max-height: 65rem;">
      <div class="card-body">
        <div class="row justify-content-center">
          <p>Store Sales Dashboard</p>
          <hr>
          <br>
          <img src="../assets/images/dashboard_ma.PNG" class="img-fluid mb-3" style="height: 300px; width: 600px;"
               data-bs-toggle="modal" data-bs-target="#imageModal1" onclick="showImage(this)">
          <b>Explanation</b>
          <p>To create the dashboard, I utilized Tableau Public. This HR dashboard focuses on monitoring employee dynamics within the company, including new hires, departures, reasons for leaving, job satisfaction levels, and employee backgrounds.

            Starting with key performance indicators (KPIs), the dashboard displays the total number of employees in the company, the active rate, attrition count, and attrition percentage. Additionally, it includes a gender-based filter to analyze the demographics of employees leaving the company.
            
            The first visual element is a pie chart illustrating department-wise attrition rates, followed by bar graphs depicting the distribution of employees across different age groups. A table presents data on job satisfaction levels based on employee ratings.</p>
        </div>
      </div>
    </div>
  </div>



  <div class="row justify-content-around mt-3 mb-5">
    <div class="card mt-5" style="max-width: 40rem; max-height: 65rem;">
      <div class="card-body">
        <div class="row justify-content-center">
          <p>Car Sales Dashboard</p>
          <hr>
          <br>
          <img src="../assets/images/car_dashboard.PNG" class="img-fluid" style="height: 300px; width: 600px;"
               data-bs-toggle="modal" data-bs-target="#imageModal2" onclick="showImage(this)">
          <b>Explanation</b>
          <p>I created this dashboard using Tableau Public,a tool with an easy-to-use interface.Dashboard mainly looks at yearly car sales and compares them to the previous year to spot any growth in sales. First, I set up key performance indicators (KPIs) that show the total sales so far this year, the total number of cars sold, and the average sales.

            Next, I added a weekly sales trend line to show how sales change week by week. A pie chart highlights the most popular car body styles sold, and a donut chart shows which car colors sold the most.
            
            In the next section, the dashboard shows year-to-date dealer performance, broken down by region. Lastly, a table lists the types of company cars sold each year and the total sales grouped by the car company.
            
            On the left side of the dashboard, users can find filters to adjust the data display.</p>
        </div>
      </div>
    </div>
  
    <div class="card mt-5" style="max-width: 40rem; max-height: 65rem;">
      <div class="card-body">
        <div class="row justify-content-center">
          <p>Call Center Dashboard</p>
          <hr>
          <br>
          <img src="../assets/images/dashboard4.PNG" class="img-fluid mb-3" style="height: 300px; width: 600px;"
               data-bs-toggle="modal" data-bs-target="#imageModal3" onclick="showImage(this)">
          <b>Explanation</b>
          <p>The dashboard built in Power BI provides insights into call center performance, showcasing key metrics such as total calls, total call duration, average call duration, and response time. It displays key performance indicators (KPIs) that highlight the total calls received, total call duration, average call duration, and response time. A bar graph illustrates the number of calls received each day of the week, with Friday being the busiest day. Additionally, a map highlights the areas from which calls are coming, while a donut chart breaks down how customers are responded to‚Äîwhether through chatbot, email, or web. The dashboard also includes sentiment analysis to provide insights into customer sentiment and features a date partition filter on the left side for easy navigation and data selection
          </p>
        </div>
      </div>
    </div>
  </div>
  <p>For more such dashboards Please visit my Tableau account "‚¨á"</p>
  <a href="https://public.tableau.com/app/profile/dilip.kumar.bairi/vizzes" target="__blank" class="nav-link"><p id="tableau">Tableau Public account-></p></a>





  
  <!-- Modal for Image Popup -->

  <div class="modal fade" id="imageModal-databricks-s3" tabindex="-1" aria-labelledby="imageModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-dialog-centered" style="max-width: 80vw; max-height: 100vh;">
      <div class="modal-content" style="height: auto; max-height: 100%;">
        <div class="modal-header">
          <h5 class="modal-title" id="imageModalLabel-databricks-s3">Exploratory Data Analysis (EDA) Using Apache Spark Leveraging Databricks</h5>
          <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
        </div>
        <div class="modal-body text-center" style="height: calc(100% - 3.5rem);">
          <img id="modalImage" src="../assets/images/databricks.svg" class="img-fluid" style="height: 60%; width: 60%; object-fit: contain;">
        
          
        <p>IPL Data Analysis Workflow
            I developed a robust data processing workflow for analyzing IPL (Indian Premier League) data:
            
            <br><b>Data Ingestion</b>: IPL data is received from various sources and stored in Amazon S3 for scalable and durable storage.
            
            <br><b>Data Processing in Databricks:</b>
            
            The data is ingested into Databricks, where I perform data cleaning and transformation to ensure quality and consistency.
            I run complex SQL queries to analyze player performances, match outcomes, and team statistics.
          </p>
          <br>
          <a href="https://github.com/bairidilipkumar/aws/tree/main/project_spark_databricks_ipl" target="_blank">GitLink</a>
        </div>
        </div>
      </div>
    </div>
  </div>

  <div class="modal fade" id="imageModal-weather-api" tabindex="-1" aria-labelledby="imageModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-dialog-centered" style="max-width: 80vw; max-height: 100vh;">
        <div class="modal-content" style="height: auto; max-height: 100%;">
            <div class="modal-header">
                <h5 class="modal-title" id="imageModalLabel">Orchestrating weather API</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body text-center d-flex flex-column align-items-center justify-content-center" style="overflow-y: auto; max-height: calc(100vh - 150px);">
                <img id="modalImage" src="../assets/images/Normal-weather-api-airflow.svg" class="img-fluid" style="height: 60%; width: 60%; object-fit: contain;">
                <p class="mt-3">Airflow is used to orchestrate the tasks by creating DAGs, so I did this project to know more about the Airflow workflow.
                    <br><b>API Integration:</b> Configured Airflow to connect with the Open Weather API, enabling automated data extraction based on predefined schedules.
                    <br><b>Data Extraction:</b> Created a task to fetch weather data from the API, ensuring relevant parameters were collected for further processing.
                    <br><b>Data Processing:</b> Implemented transformations on the extracted data, cleaning and organizing it to meet storage and analysis requirements.
                    <br><b>Data Storage:</b> Developed a task to store the processed data in Amazon S3, ensuring it was securely saved and easily accessible for future use.
                </p>
                <a href="https://github.com/bairidilipkumar/aws/tree/main/airflow-projects" target="_blank" class="mt-2">GitLink</a>
            </div>
        </div>
    </div>
</div>




  <div class="modal fade" id="imageModal-airflow-s3" tabindex="-1" aria-labelledby="imageModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-dialog-centered" style="max-width: 80vw; max-height: 100vh;">
        <div class="modal-content" style="height: auto; max-height: 100%;">
            <div class="modal-header">
                <h5 class="modal-title" id="imageModal-airflow-s3">Orchestrating weather API with Airflow to S3</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body text-center" style="overflow-y: auto; max-height: calc(100vh - 150px);">
                <img id="modalImage" src="../assets/images/weather-api-s3-email.svg" class="img-fluid" style="height: auto; width: 60%; object-fit: contain;">
                <p><br>
                    <b>Data Orchestration with Airflow:</b> Initially, we orchestrate the fetching of weather data using Apache Airflow. This allows us to automate the data collection process efficiently.
                    <br><b>Storing Data in S3:</b> Once the data is fetched, it is stored in Amazon S3 (Simple Storage Service). S3 serves as a reliable storage solution, ensuring that our weather data is easily accessible and secure.
                    <br><b>Triggering Processing with S3 Events:</b> To enhance the responsiveness of our system, we will implement S3 event notifications. These notifications will be triggered whenever new data is added to S3.
                    <br><b>Data Processing with AWS Lambda:</b> When new data is uploaded to S3, it will automatically trigger an AWS Lambda function. This serverless function will process the incoming weather data, ensuring it is formatted and ready for distribution.
                    <br><b>Distributing Weather Forecasts:</b> The processed weather data will then be sent to various destinations, such as news channels and other services, every hour. This timely distribution ensures that the latest weather forecasts are available for broadcasting and public use.
                </p>
            </div>
        </div>
    </div>
</div>



  <div class="modal fade" id="imageModal-glue" tabindex="-1" aria-labelledby="imageModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-dialog-centered" style="max-width: 80vw; max-height: 100vh;">
        <div class="modal-content" style="height: auto; max-height: 100%;">
            <div class="modal-header">
                <h5 class="modal-title" id="imageModalLabel">AWS ETL pipeline Project</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body text-center" style="overflow-y: auto; max-height: calc(100vh - 150px);">
                <img id="modalImage" src="../assets/images/glue.gif" class="img-fluid" style="height: auto; width: 60%; object-fit: contain;">
                <p></p>
                <p>Scalability and Operational Efficiency:<br>
                    <b>On-Demand Scalability:</b> The use of AWS Glue for ETL and crawlers, along with Amazon Athena for querying, allows the pipeline to scale according to the volume of data and query load, accommodating changing requirements without significant manual intervention.
                    <br><b>Low Operational Overhead:</b> This orchestration minimizes the need for extensive management and maintenance efforts, allowing your team to focus on data insights rather than infrastructure management.
                    <br><b>Good Latency:</b> Despite the slightly higher costs, the combination of these services ensures efficient processing and querying, delivering insights quickly to support informed decision-making.
                </p>
            </div>
        </div>
    </div>
</div>





  <div class="modal fade" id="imageModal" tabindex="-1" aria-labelledby="imageModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-dialog-centered" style="max-width: 80vw; max-height: 80vh;">
      <div class="modal-content" style="height: 100%;">
        <div class="modal-header">
          <h5 class="modal-title" id="imageModalLabel">HR Dashboard</h5>
          <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
        </div>
        <div class="modal-body text-center" style="height: calc(100% - 3.5rem);">
          <img id="modalImage" src="../assets/images/hr_dashboard.PNG" class="img-fluid" style="height: 100%; width: 100%; object-fit: contain;">
        </div>
      </div>
    </div>
  </div>
  
  <div class="modal fade" id="imageModal1" tabindex="-1" aria-labelledby="imageModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-dialog-centered modal-lg">
      <div class="modal-content">
        <div class="modal-header">
          <h5 class="modal-title" id="imageModalLabel">Sales Dashboard</h5>
          <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
        </div>
        <div class="modal-body text-center">
          <img id="modalImage" src="../assets/images/dashboard_ma.PNG" class="img-fluid">
        </div>
      </div>
    </div>
  </div>

  <div class="modal fade" id="imageModal2" tabindex="-1" aria-labelledby="imageModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-dialog-centered modal-lg">
      <div class="modal-content">
        <div class="modal-header">
          <h5 class="modal-title" id="imageModalLabel">Car Sales Dashboard</h5>
          <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
        </div>
        <div class="modal-body text-center">
          <img id="modalImage" src="../assets/images/car_dashboard.PNG" class="img-fluid">
        </div>
      </div>
    </div>
  </div>

  <div class="modal fade" id="imageModal3" tabindex="-1" aria-labelledby="imageModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-dialog-centered modal-lg">
      <div class="modal-content">
        <div class="modal-header">
          <h5 class="modal-title" id="imageModalLabel">Call Center Dashboard</h5>
          <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
        </div>
        <div class="modal-body text-center">
          <img id="modalImage" src="../assets/images/dashboard4.PNG" class="img-fluid">
        </div>
      </div>
    </div>
  </div>
  
  <script>
    function showImage(element) {
      const modalImage = document.getElementById('modalImage');
      modalImage.src = element.src;
    }
  </script>
  